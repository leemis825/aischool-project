import { useNavigate } from "react-router-dom";
import Layout from "../components/Layout.js";
import { useEffect, useRef, useState } from "react";
// ì–¸ë‹ˆ ì—¬ê¸°ì˜ˆìš”1ğŸ¦ŠğŸ°
import { sttAndMinwon, type SttMinwonResponse } from "../services/sttService";
import { requestTts } from "../services/ttsService";
import SpeakerImg from "../assets/speaker.png";
import { saveComplaintFromStt } from "../services/complaintService";

export default function ListeningPage() {
  const navigate = useNavigate();

  const [isRecording, setIsRecording] = useState(false);
  const [isUploading, setIsUploading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [sttResult, setSttResult] = useState<string>("");
  const [ttsUrl, setTtsUrl] = useState<string | null>(null); // ğŸ”¹ ì‚¬ìš©ì ì•ˆë‚´ TTS URL
  const [volume, setVolume] = useState(0);
  const [sessionId, setSessionId] = useState<string | null>(null); // ğŸ”¹ ë°±ì—”ë“œ ì„¸ì…˜ ID
  const sessionIdRef = useRef<string | null>(null);

  // ğŸ”¹ StrictModeì—ì„œ useEffect ë‘ ë²ˆ ì‹¤í–‰ë˜ëŠ” ê²ƒ ë°©ì§€ìš©
  const hasInitRef = useRef(false);

  // ğŸ”¹ ë…¹ìŒ ê´€ë ¨ refë“¤
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);

  // ğŸ”¹ ì˜¤ë””ì˜¤ ë¹„ì£¼ì–¼ë¼ì´ì €ìš© refë“¤
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null); // í˜„ì¬ëŠ” ì•ˆ ì“°ì§€ë§Œ ë‚¨ê²¨ë‘ (í™•ì¥ìš©)

  // ğŸ”Š ë³¼ë¥¨ ê³„ì‚° â†’ ì´ë¯¸ì§€ íŠ•ê¹€ìš©
  const trackVolume = () => {
    const analyser = analyserRef.current;
    if (!analyser) return;

    const bufferLength = analyser.fftSize;
    const dataArray = new Uint8Array(bufferLength);

    const update = () => {
      animationFrameRef.current = requestAnimationFrame(update);

      analyser.getByteTimeDomainData(dataArray);

      let sum = 0;
      for (let i = 0; i < bufferLength; i++) {
        const v = (dataArray[i] ?? 128) - 128;
        sum += Math.abs(v);
      }
      const avg = sum / bufferLength; // 0~128
      const normalized = Math.min(avg / 64, 1); // 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”

      setVolume(normalized);
    };

    update();
  };

  const stopVisualizer = () => {
    // ì• ë‹ˆë©”ì´ì…˜ ë£¨í”„ ì¤‘ì§€
    if (animationFrameRef.current !== null) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    // ìº”ë²„ìŠ¤ ê¹¨ë—í•˜ê²Œ ì§€ìš°ê³  ë°°ê²½ë§Œ ì±„ìš°ê¸° (í˜„ì¬ UIì—ëŠ” ì•ˆ ë³´ì—¬ë„ ë°©ì–´ìš©)
    const canvas = canvasRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    const { width, height } = canvas;
    ctx.clearRect(0, 0, width, height);
    ctx.fillStyle = "#4E9948";
    ctx.fillRect(0, 0, width, height);
  };

  // ğŸ”¹ ë…¹ìŒ + ë³¼ë¥¨ ì¶”ì  ì„¸íŒ…
  const setupRecorderAndVisualizer = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: true,
      });
      mediaStreamRef.current = stream;

      /**
       * 1) MediaRecorder ì„¤ì • (ë…¹ìŒìš©)
       */
      const options: MediaRecorderOptions = {};
      if (MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) {
        options.mimeType = "audio/webm;codecs=opus";
      } else if (MediaRecorder.isTypeSupported("audio/webm")) {
        options.mimeType = "audio/webm";
      }

      const recorder = new MediaRecorder(stream, options);

      recorder.ondataavailable = (event: BlobEvent) => {
        if (event.data && event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      recorder.onstop = async () => {
        try {
          const blob = new Blob(chunksRef.current, { type: "audio/webm" });
          chunksRef.current = [];

          await uploadBlob(blob);
        } catch (err) {
          console.error(err);
          setError("ë…¹ìŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.");
          setIsUploading(false);
        }
      };

      mediaRecorderRef.current = recorder;

      /**
       * 2) AudioContext + Analyser ì„¤ì • (ë³¼ë¥¨ ì¸¡ì •ìš©)
       */
      const audioCtx = new (window.AudioContext ||
        (window as any).webkitAudioContext)();
      audioContextRef.current = audioCtx;

      const source = audioCtx.createMediaStreamSource(stream);
      const analyser = audioCtx.createAnalyser();
      analyser.fftSize = 2048; // í•´ìƒë„
      source.connect(analyser);
      analyserRef.current = analyser;

      if (analyserRef.current) {
        trackVolume();
      }

      // ğŸ”´ ì—¬ê¸°ì„œë¶€í„° ì‹¤ì œ ë…¹ìŒ ì‹œì‘
      recorder.start();
      setIsRecording(true);
      setIsUploading(false);
      setError(null);
    } catch (e) {
      console.error(e);
      setError("ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ ì£¼ì„¸ìš”.");
    }
  };

  // ğŸ”Š í˜ì´ì§€ ì§„ì… ì‹œ: ì•ˆë‚´ ë©˜íŠ¸ â†’ ëë‚˜ë©´ ë…¹ìŒ ì‹œì‘
  useEffect(() => {
    if (hasInitRef.current) return;
    hasInitRef.current = true;

    const speakAndStart = async () => {
      try {
        const text =
          "ë§ì”€ì„ ë“£ê³  ìˆì–´ìš”. ë§ì”€ì´ ëë‚˜ë©´ í™”ë©´ ì–´ë””ë“  ëˆŒëŸ¬ ì£¼ì„¸ìš”.";
        console.log("[ListeningPage] ì•ˆë‚´ TTS:", text);
        const blob = await requestTts(text);
        const url = URL.createObjectURL(blob);
        const audio = new Audio(url);

        audio.onended = () => {
          URL.revokeObjectURL(url);
          setupRecorderAndVisualizer();
        };

        audio.onerror = () => {
          URL.revokeObjectURL(url);
          // ì¬ìƒ ì‹¤íŒ¨í•´ë„ ë°”ë¡œ ë…¹ìŒ ì‹œì‘
          setupRecorderAndVisualizer();
        };

        audio.play();
      } catch (e) {
        console.error("ListeningPage ì•ˆë‚´ ìŒì„± ì˜¤ë¥˜:", e);
        // TTS í˜¸ì¶œ ìì²´ê°€ ì‹¤íŒ¨í•´ë„ ë…¹ìŒì€ ì‹œì‘
        setupRecorderAndVisualizer();
      }
    };

    speakAndStart();

    // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    return () => {
      try {
        if (
          mediaRecorderRef.current &&
          mediaRecorderRef.current.state !== "inactive"
        ) {
          mediaRecorderRef.current.stop();
        }
      } catch {
        // ignore
      }

      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach((t) => t.stop());
      }

      if (animationFrameRef.current !== null) {
        cancelAnimationFrame(animationFrameRef.current);
      }

      if (audioContextRef.current) {
        audioContextRef.current.close();
      }

      stopVisualizer();
    };
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // ì–¸ë‹ˆ ì—¬ê¸°ì˜ˆìš”2ğŸ¦ŠğŸ°
  // STT ê²°ê³¼ì— ëŒ€í•œ ì•ˆë‚´ ë©˜íŠ¸(TTS) ì¬ìƒìš©
  const callTTS = async (text: string) => {
    try {
      const trimmed = text?.trim();
      if (!trimmed) return;

      // ì´ì „ì— ë§Œë“  ì˜¤ë””ì˜¤ URLì´ ìˆìœ¼ë©´ ì •ë¦¬
      if (ttsUrl) {
        URL.revokeObjectURL(ttsUrl);
      }

      const blob = await requestTts(trimmed);
      const url = URL.createObjectURL(blob);
      setTtsUrl(url);
    } catch (e) {
      console.error(e);
      setError("ì•ˆë‚´ ìŒì„±ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.");
    }
  };

  const uploadBlob = async (blob: Blob) => {
    setError(null);

    try {
      console.log("ğŸ¤ì „ì†¡í•  ì˜¤ë””ì˜¤ Blob:", blob);
      console.log(
        "ğŸ‘‰ uploadBlob ì§ì „ sessionIdRef.current =",
        sessionIdRef.current
      );

      const file = new File([blob], "voice.webm", { type: "audio/webm" });

      // ğŸ”¥ ì´ë¯¸ ì„¸ì…˜ IDê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ê³„ì† ì‚¬ìš©
      const result: SttMinwonResponse = await sttAndMinwon(
        file,
        sessionIdRef.current
      );
      console.log("ğŸ”Š STT+ë¯¼ì› ì—”ì§„ ê²°ê³¼:", result);

      if (result.engine_result) {
        sessionStorage.setItem(
          "last_engine_result",
          JSON.stringify(result.engine_result)
        );
      }

      const finalText = result.text || "(ë¹ˆ í…ìŠ¤íŠ¸)";
      setSttResult(finalText);
      setIsUploading(false);

      // âœ… ì„¸ì…˜ IDëŠ” "ì²˜ìŒ í•œ ë²ˆë§Œ" ì„¸íŒ…
      if (!sessionIdRef.current && result.session_id) {
        sessionIdRef.current = result.session_id;
        setSessionId(result.session_id);
        console.log("âœ… ì„¸ì…˜ ID ìµœì´ˆ ì„¤ì •:", result.session_id);
        sessionStorage.setItem("last_session_id", result.session_id);
      } else if (
        sessionIdRef.current &&
        result.session_id &&
        result.session_id !== sessionIdRef.current
      ) {
        console.warn(
          "âš ï¸ ì„œë²„ê°€ ë‹¤ë¥¸ session_idë¥¼ ëŒë ¤ì¤¬ì–´ìš”. ê¸°ì¡´ ê²ƒì„ ìœ ì§€í•©ë‹ˆë‹¤.",
          {
            current: sessionIdRef.current,
            returned: result.session_id,
          }
        );
        // ì—¬ê¸°ì„œëŠ” ê·¸ëƒ¥ ë¬´ì‹œí•˜ê³  ê¸°ì¡´ sessionIdRef.currentë¥¼ ê³„ì† ì‚¬ìš©
      }
      try {
        await saveComplaintFromStt(result, null);
      } catch (err) {
        console.error("ë¯¼ì› ì €ì¥ ì¤‘ ì˜¤ë¥˜(í™”ë©´ íë¦„ì€ ê³„ì† ì§„í–‰):", err);
        // êµ³ì´ ì‚¬ìš©ìì—ê²Œ ì—ëŸ¬ í‘œì‹œ ì•ˆ í•˜ê³ , íë¦„ë§Œ ì´ì–´ê°€ë„ ë¨
      }

      await callTTS(
        result.user_facing?.main_message ??
          "ë§ì”€í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."
      );

      const stage = result.engine_result?.stage;

      if (stage === "clarification") {
        console.log("ğŸ” clarification ë‹¨ê³„ â€“ ë‹¤ì‹œ ë…¹ìŒ ëŒ€ê¸°");
        await setupRecorderAndVisualizer();
        return;
      }

      navigate("/summary", {
        state: {
          sttText: finalText,
          summary: result.staff_payload?.summary,
          engineResult: result.engine_result,
        },
      });
    } catch (e) {
      console.error(e);
      setError("ë…¹ìŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.");
      setIsUploading(false);
    }
  };

  // ğŸ”¹ í™”ë©´ íƒ­ ì‹œ: ë…¹ìŒ ì¢…ë£Œ + ì—…ë¡œë“œ
  const handleClick = () => {
    if (!isRecording || isUploading) return;
    if (!mediaRecorderRef.current) {
      setError("ë…¹ìŒê¸°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ì–´ìš”.");
      return;
    }

    setIsUploading(true);

    try {
      mediaRecorderRef.current.stop();
      setIsRecording(false);

      // ğŸ”¥ ì—¬ê¸°ì„œ ë³¼ë¥¨ ì• ë‹ˆë©”ì´ì…˜ ë„ê¸°
      stopVisualizer();
    } catch (e) {
      console.error(e);
      setError("ë…¹ìŒì„ ì¤‘ë‹¨í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.");
      setIsUploading(false);
    }
  };

  return (
    <Layout
      title="ë¯¼ì›ì ‘ìˆ˜"
      content="ë§ì”€ì„ ë“£ê³  ìˆì–´ìš”"
      topImage="src/assets/top2.png"
      onClick={handleClick}
    >
      <div
        style={{
          display: "flex",
          justifyContent: "center",
          alignItems: "center",
          flexDirection: "column",
          marginTop: "25px",
        }}
      >
        <img
          src={SpeakerImg}
          alt="speaker"
          style={{
            width: "230px",
            height: "230px",
            marginTop: "-50px",
            marginBottom: "20px",
            transition: "transform 0.05s linear",
            transform:
              isRecording && !isUploading
                ? `scale(${1 + Math.sin(volume * 10) * 0.2})` // ğŸ”Š ë…¹ìŒ ì¤‘ì—ë§Œ ê¿ˆí‹€
                : "scale(1)", // ğŸ”‡ ì•„ë‹ˆë©´ ê³ ì •
          }}
        />

        {error && <p style={{ color: "red" }}>{error}</p>}
        {isRecording && !isUploading && !error && (
          <h2>ë§ì”€ì´ ëë‚˜ë©´ í™”ë©´ ì–´ë””ë“  ëˆŒëŸ¬ì£¼ì„¸ìš”</h2>
        )}
        {isUploading && <h2>ì¸ì‹ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...</h2>}
        {sttResult && !isUploading}

        {ttsUrl && !isUploading && (
          <div style={{ marginTop: 16 }}>
            <audio src={ttsUrl} controls autoPlay />
          </div>
        )}
      </div>
    </Layout>
  );
}
